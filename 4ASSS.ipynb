{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_f7IX5cS78f",
        "outputId": "8ebbe6f6-9d51-4536-df28-b66b1f12e7e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Train: 1.000, Test: 0.912\n",
            "Pruned Train: 0.976, Test: 0.939\n",
            "Random Train: 1.000, Random Test: 0.956\n",
            "Top 5 : worst area              0.140016\n",
            "worst concave points    0.129530\n",
            "worst radius            0.097696\n",
            "mean concave points     0.090885\n",
            "worst perimeter         0.072226\n",
            "dtype: float64\n",
            "Gradient Boosting Accuracy Train: 1.000, Test: 0.956\n",
            " Gradient Boosting Hyperparameter Sweep \n",
            "lr | n_estimators | train_acc | test_acc\n",
            "0.01 | 50           | 0.976    | 0.939\n",
            "0.01 | 100          | 0.987    | 0.921\n",
            "0.01 | 200          | 0.993    | 0.930\n",
            "0.1  | 50           | 1.000    | 0.947\n",
            "0.1  | 100          | 1.000    | 0.956\n",
            "0.1  | 200          | 1.000    | 0.956\n",
            "Top 5  worst radius            0.435471\n",
            "worst perimeter         0.271465\n",
            "worst concave points    0.106543\n",
            "worst texture           0.052636\n",
            "mean concave points     0.030458\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "dt_full = DecisionTreeClassifier(random_state=42)\n",
        "dt_full.fit(X_train, y_train)\n",
        "y_train_dt_full = dt_full.predict(X_train)\n",
        "y_test_dt_full = dt_full.predict(X_test)\n",
        "\n",
        "dt_pruned = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "dt_pruned.fit(X_train, y_train)\n",
        "y_train_dt_pruned = dt_pruned.predict(X_train)\n",
        "y_test_dt_pruned = dt_pruned.predict(X_test)\n",
        "\n",
        "print(f\"Full Train: {accuracy_score(y_train, y_train_dt_full):.3f}, Test: {accuracy_score(y_test, y_test_dt_full):.3f}\")\n",
        "print(f\"Pruned Train: {accuracy_score(y_train, y_train_dt_pruned):.3f}, Test: {accuracy_score(y_test, y_test_dt_pruned):.3f}\")\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "y_train_rf = rf.predict(X_train)\n",
        "y_test_rf = rf.predict(X_test)\n",
        "\n",
        "print(f\"Random Train: {accuracy_score(y_train, y_train_rf):.3f}, Random Test: {accuracy_score(y_test, y_test_rf):.3f}\")\n",
        "\n",
        "rf_importance = pd.Series(rf.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
        "print(\"Top 5 :\", rf_importance.head(5))\n",
        "\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "y_train_gb = gb.predict(X_train)\n",
        "y_test_gb = gb.predict(X_test)\n",
        "\n",
        "print(f\"Gradient Boosting Accuracy Train: {accuracy_score(y_train, y_train_gb):.3f}, Test: {accuracy_score(y_test, y_test_gb):.3f}\")\n",
        "learning_rates = [0.01, 0.1]\n",
        "n_estimators_list = [50, 100, 200]\n",
        "\n",
        "print(\" Gradient Boosting Hyperparameter Sweep \")\n",
        "print(\"lr | n_estimators | train_acc | test_acc\")\n",
        "for lr in learning_rates:\n",
        "    for n_est in n_estimators_list:\n",
        "        gb = GradientBoostingClassifier(learning_rate=lr, n_estimators=n_est, random_state=42)\n",
        "        gb.fit(X_train, y_train)\n",
        "        train_acc = accuracy_score(y_train, gb.predict(X_train))\n",
        "        test_acc = accuracy_score(y_test, gb.predict(X_test))\n",
        "        print(f\"{lr:<4} | {n_est:<12} | {train_acc:.3f}    | {test_acc:.3f}\")\n",
        "\n",
        "importance = pd.Series(gb.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
        "print(\"Top 5 \", importance.head(5))\n"
      ]
    }
  ]
}